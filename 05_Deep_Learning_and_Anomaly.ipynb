{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5610d1f7-e1f3-4bae-b489-f0f00d928702",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03dcb1c0-3534-401d-bb27-8e95fd6cf5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 19:42:49.811004: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-20 19:43:14.613088: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-20 19:43:26.383614: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TensorFlow / Keras for MLP & Autoencoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1219ef3-fe11-485f-b2be-f81d3ca7f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e6ae3a-e888-419a-a1e3-1b6d88242fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Helper function for PR AUC\n",
    "# -----------------------------\n",
    "def compute_pr_auc(y_true, y_scores):\n",
    "    from sklearn.metrics import precision_recall_curve, auc\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    return auc(recall, precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e65125-2540-4e76-9776-9a6ee16cb2a2",
   "metadata": {},
   "source": [
    "####  Ensure folders exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629710ea-e079-4ff1-a3be-f6e52c8bbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACTS_DIR = Path(\"artifacts\")\n",
    "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22723d8-8265-4898-94c0-f03337629afe",
   "metadata": {},
   "source": [
    "#### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46ebe6ce-cdd1-46df-833e-8a3429c28307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/scaler.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = joblib.load(ARTIFACTS_DIR / \"data_splits.pkl\")\n",
    "X_train, y_train = data[\"X_train\"], data[\"y_train\"]\n",
    "X_val, y_val     = data[\"X_val\"], data[\"y_val\"]\n",
    "\n",
    "# Scale numeric features for MLP / Autoencoder / SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Save scaler for deployment\n",
    "joblib.dump(scaler, MODELS_DIR / \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa78f8b-5a72-4823-95bb-eb49df9042ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Dictionary to store metrics\n",
    "# -----------------------------\n",
    "metrics_deep_anomaly = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d0bfe-0aca-4aad-9737-2e2bf6308387",
   "metadata": {},
   "source": [
    "## MLP Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945bccff-1ed3-4e4f-bc49-0bda99be5fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 19:46:45.001900: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP metrics: {'roc_auc': 0.9078172261301838, 'pr_auc': 0.553612900240347, 'f1': 0.5503432494279176, 'precision': 0.492827868852459, 'recall': 0.6230569948186528}\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "mlp.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "mlp.fit(X_train_scaled, y_train, validation_data=(X_val_scaled, y_val), epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "y_val_proba_mlp = mlp.predict(X_val_scaled).ravel()\n",
    "y_val_pred_mlp = (y_val_proba_mlp >= 0.5).astype(int)\n",
    "\n",
    "metrics_deep_anomaly[\"MLP\"] = {\n",
    "    \"roc_auc\": roc_auc_score(y_val, y_val_proba_mlp),\n",
    "    \"pr_auc\": compute_pr_auc(y_val, y_val_proba_mlp),\n",
    "    \"f1\": f1_score(y_val, y_val_pred_mlp),\n",
    "    \"precision\": precision_score(y_val, y_val_pred_mlp),\n",
    "    \"recall\": recall_score(y_val, y_val_pred_mlp)\n",
    "}\n",
    "\n",
    "mlp.save(MODELS_DIR / \"mlp.h5\")\n",
    "print(\"MLP metrics:\", metrics_deep_anomaly[\"MLP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68aeb48-2379-4b7a-a586-7cde5f678a0d",
   "metadata": {},
   "source": [
    "## IsolationForest (Anomaly Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cddce53f-2c16-44fc-bbed-be038ce638eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest metrics: {'roc_auc': 0.6029977655197114, 'pr_auc': 0.21658276280320338, 'f1': 0.2486910994764398, 'precision': 0.15583989501312337, 'recall': 0.6152849740932642}\n"
     ]
    }
   ],
   "source": [
    "iso = IsolationForest(n_estimators=200, contamination=0.1, random_state=42)\n",
    "iso.fit(X_train_scaled)\n",
    "\n",
    "# Anomaly score (flip sign so higher = more likely positive)\n",
    "y_val_scores_iso = -iso.decision_function(X_val_scaled)\n",
    "\n",
    "# Convert scores to binary predictions using median threshold\n",
    "threshold = np.median(y_val_scores_iso)\n",
    "y_val_pred_iso = (y_val_scores_iso >= threshold).astype(int)\n",
    "\n",
    "metrics_deep_anomaly[\"IsolationForest\"] = {\n",
    "    \"roc_auc\": roc_auc_score(y_val, y_val_scores_iso),\n",
    "    \"pr_auc\": compute_pr_auc(y_val, y_val_scores_iso),\n",
    "    \"f1\": f1_score(y_val, y_val_pred_iso),\n",
    "    \"precision\": precision_score(y_val, y_val_pred_iso),\n",
    "    \"recall\": recall_score(y_val, y_val_pred_iso)\n",
    "}\n",
    "\n",
    "joblib.dump(iso, MODELS_DIR / \"isolation_forest.pkl\")\n",
    "print(\"IsolationForest metrics:\", metrics_deep_anomaly[\"IsolationForest\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d2302-1b16-4471-b8d6-6a6295d28b78",
   "metadata": {},
   "source": [
    "## One-Class SVM (Anomaly Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20d2443d-6eda-478a-bef3-fd1932a0c46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Class SVM metrics: {'roc_auc': 0.6043174324497923, 'pr_auc': 0.19582352711694906, 'f1': 0.2591623036649215, 'precision': 0.1624015748031496, 'recall': 0.6411917098445595}\n"
     ]
    }
   ],
   "source": [
    "ocsvm = OneClassSVM(kernel='rbf', gamma='scale', nu=0.05)\n",
    "ocsvm.fit(X_train_scaled)\n",
    "\n",
    "y_val_scores_ocsvm = -ocsvm.decision_function(X_val_scaled)\n",
    "threshold_ocsvm = np.median(y_val_scores_ocsvm)\n",
    "y_val_pred_ocsvm = (y_val_scores_ocsvm >= threshold_ocsvm).astype(int)\n",
    "\n",
    "metrics_deep_anomaly[\"OneClassSVM\"] = {\n",
    "    \"roc_auc\": roc_auc_score(y_val, y_val_scores_ocsvm),\n",
    "    \"pr_auc\": compute_pr_auc(y_val, y_val_scores_ocsvm),\n",
    "    \"f1\": f1_score(y_val, y_val_pred_ocsvm),\n",
    "    \"precision\": precision_score(y_val, y_val_pred_ocsvm),\n",
    "    \"recall\": recall_score(y_val, y_val_pred_ocsvm)\n",
    "}\n",
    "\n",
    "joblib.dump(ocsvm, MODELS_DIR / \"one_class_svm.pkl\")\n",
    "print(\"One-Class SVM metrics:\", metrics_deep_anomaly[\"OneClassSVM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd44438b-5a53-4c55-8bba-d1ce2c499f21",
   "metadata": {},
   "source": [
    "## Autoencoder (Unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d80e1971-f5d1-477e-ab09-a8cf8c7e8941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder metrics: {'roc_auc': 0.6452901223514207, 'pr_auc': 0.22554583633013764, 'f1': 0.268586387434555, 'precision': 0.16830708661417323, 'recall': 0.6645077720207254}\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_scaled.shape[1]\n",
    "encoding_dim = 32\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(64, activation='relu')(input_layer)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(X_train_scaled, X_train_scaled, \n",
    "                validation_data=(X_val_scaled, X_val_scaled),\n",
    "                epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "# Reconstruction error as anomaly score\n",
    "X_val_pred = autoencoder.predict(X_val_scaled)\n",
    "reconstruction_error = np.mean((X_val_scaled - X_val_pred)**2, axis=1)\n",
    "\n",
    "threshold_ae = np.median(reconstruction_error)\n",
    "y_val_pred_ae = (reconstruction_error >= threshold_ae).astype(int)\n",
    "\n",
    "metrics_deep_anomaly[\"Autoencoder\"] = {\n",
    "    \"roc_auc\": roc_auc_score(y_val, reconstruction_error),\n",
    "    \"pr_auc\": compute_pr_auc(y_val, reconstruction_error),\n",
    "    \"f1\": f1_score(y_val, y_val_pred_ae),\n",
    "    \"precision\": precision_score(y_val, y_val_pred_ae),\n",
    "    \"recall\": recall_score(y_val, y_val_pred_ae)\n",
    "}\n",
    "\n",
    "autoencoder.save(MODELS_DIR / \"autoencoder.h5\")\n",
    "print(\"Autoencoder metrics:\", metrics_deep_anomaly[\"Autoencoder\"])\n",
    "\n",
    "# -----------------------------\n",
    "# Save metrics to JSON\n",
    "# -----------------------------\n",
    "with open(ARTIFACTS_DIR / \"metrics_deep_anomaly.json\", \"w\") as f:\n",
    "    json.dump(metrics_deep_anomaly, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c447820a-78fa-4ad5-a000-052ac0782721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Deep Learning and anomaly models trained, metrics and models saved\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Deep Learning and anomaly models trained, metrics and models saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20210123-6c6b-4693-bea5-4e9e7d9cf50e",
   "metadata": {},
   "source": [
    "✅ Key Notes\n",
    "\n",
    "MLP → simple feedforward neural network for binary classification.\n",
    "\n",
    "IsolationForest & One-Class SVM → unsupervised anomaly detection; anomaly scores converted to binary using median threshold.\n",
    "\n",
    "Autoencoder → reconstruction error used as anomaly score.\n",
    "\n",
    "Metrics → ROC AUC, PR AUC, F1, Precision, Recall\n",
    "\n",
    "Saved artifacts:\n",
    "\n",
    "artifacts/metrics_deep_anomaly.json\n",
    "\n",
    "models/mlp.h5\n",
    "\n",
    "models/isolation_forest.pkl\n",
    "\n",
    "models/one_class_svm.pkl\n",
    "\n",
    "models/autoencoder.h5\n",
    "\n",
    "Scaler saved → ensures all downstream notebooks and deployment use the same preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ae432-fe20-4a36-8f64-adb862cf8841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
